# Real-time Data Pipeline with Kafka, Flink and BigQuery
## (Há»‡ thá»‘ng xá»­ lÃ½ dá»¯ liá»‡u thá»i gian thá»±c sá»­ dá»¥ng Kafka, Flink vÃ  BigQuery)

## ğŸ“Œ Má»¥c Ä‘Ã­ch/Má»¥c tiÃªu (Purpose)
XÃ¢y dá»±ng pipeline xá»­ lÃ½ dá»¯ liá»‡u clickstream thá»i gian thá»±c:
- **Producer**: Táº¡o dá»¯ liá»‡u clickstream giáº£ láº­p
- **Kafka**: Trung gian truyá»n dá»¯ liá»‡u
- **Flink**: Xá»­ lÃ½ dá»¯ liá»‡u thá»i gian thá»±c
- **BigQuery**: LÆ°u trá»¯ káº¿t quáº£

(Build a real-time clickstream processing pipeline:
- **Producer**: Generates synthetic clickstream data
- **Kafka**: Message broker
- **Flink**: Real-time processing
- **BigQuery**: Storage for processed results)

## ğŸ›  CÃ´ng nghá»‡ sá»­ dá»¥ng (Technology Stack)
- **Apache Kafka** (Message Broker)
- **Apache Flink** (Stream Processing)
- **Google BigQuery** (Data Warehouse)
- **Python** (Producer & Flink Job)
- **Docker** (Containerization)

## ğŸš€ CÃ¡ch cháº¡y (How to Run)

### Äiá»u kiá»‡n tiÃªn quyáº¿t (Prerequisites)
- Docker Desktop
- Python 3.7+
- GCP Service Account Key


### 1. Khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng (Start Infrastructure)
```bash
docker-compose up -d
```

### 2. Cháº¡y Kafka Producer
```bash
cd kafka-producer
pip install -r requirements.txt
python producer.py
```

### 3.1 Setup env Flink Job
```bash
docker exec -it ex1-jobmanager-1 /bin/bash

apt-get update && apt-get install -y python3 python3-pip

ln -s /usr/bin/python3 /usr/bin/python

pip install -r /opt/flink/usrlib/src/main/python/requirements.txt

echo "python.executable: /usr/bin/python3.10" >> /opt/flink/conf/flink-conf.yaml
echo "python.client.executable: /usr/bin/python3.10" >> /opt/flink/conf/flink-conf.yaml

export PYFLINK_EXECUTABLE=/usr/bin/python3.10
export PYFLINK_PYTHON=/usr/bin/python3.10
export PYTHONPATH=/opt/flink/usrlib/src/main/python
```

### 3.2 Submit Flink Job
```bash
docker exec -it flink-jobmanager_1 \
  PYFLINK_EXECUTABLE=/usr/bin/python3.10 PYFLINK_PYTHON=/usr/bin/python3.10 flink run -py stream-process.py -pyexec /usr/bin/python3.10 -pyfs /opt/flink/usrlib/src/main/python
```

### 4. GiÃ¡m sÃ¡t (Monitoring)
- **Kafka UI**: http://localhost:8080
- **Flink Dashboard**: http://localhost:8081
- **BigQuery**: Truy cáº­p GCP Console

## ğŸ“‚ Cáº¥u trÃºc thÆ° má»¥c (Project Structure)
```
.
â”œâ”€â”€ docker-compose.yml          # Docker configuration
â”œâ”€â”€ kafka-producer/            # Kafka producer code
â”‚   â”œâ”€â”€ producer.py            # Clickstream generator
â”‚   â””â”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ flink-job/                 # Flink processing
    â”œâ”€â”€ src/main/python/       # Flink Python code
    â”‚   â””â”€â”€ stream_processor.py 
    â””â”€â”€ src/main/resources/    # GCP credentials
        â””â”€â”€ gcp_credentials.json
```

## âš™ Cáº¥u hÃ¬nh (Configuration)
| File | Má»¥c Ä‘Ã­ch (Purpose) |
|------|-------------------|
| `docker-compose.yml` | Cáº¥u hÃ¬nh Kafka, Flink containers |
| `producer.py` | Táº¡o dá»¯ liá»‡u clickstream ngáº«u nhiÃªn |
| `stream_processor.py` | Xá»­ lÃ½ dá»¯ liá»‡u vÃ  ghi vÃ o BigQuery |

## ğŸ” Kiá»ƒm tra dá»¯ liá»‡u (Data Verification)
```sql
-- BigQuery SQL
SELECT * FROM `your-project.clickstream_dataset.user_activity` 
ORDER BY processing_time DESC LIMIT 10
```

## ğŸ›  Kháº¯c phá»¥c sá»± cá»‘ (Troubleshooting)
1. **Kafka connection issues**:
   ```bash
   docker exec -it kafka kafka-topics --list --bootstrap-server kafka:29092
   ```

2. **Flink job failures**:
   ```bash
   docker logs flink-jobmanager_1
   ```

3. **BigQuery permissions**:
   - Kiá»ƒm tra Service Account cÃ³ quyá»n `BigQuery Data Editor`



